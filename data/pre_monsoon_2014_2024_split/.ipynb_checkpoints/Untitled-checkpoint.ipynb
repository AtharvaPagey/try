{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7350b8ae-a0f6-4743-a64a-01ecd37883e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/pre_monsoon_1994_2003_split/pre_monsoon_1994_2003-2001-3047.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# --- FIX: Define line_buffer OUTSIDE the page loop ---\u001b[39;00m\n\u001b[32m     15\u001b[39m line_buffer = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpdfplumber\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pdf:\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m pdf.pages:\n\u001b[32m     19\u001b[39m         text = page.extract_text()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\pdftoexcelconv\\Lib\\site-packages\\pdfplumber\\pdf.py:98\u001b[39m, in \u001b[36mPDF.open\u001b[39m\u001b[34m(cls, path_or_fp, pages, laparams, password, strict_metadata, unicode_norm, repair, gs_path, repair_setting, raise_unicode_errors)\u001b[39m\n\u001b[32m     96\u001b[39m     path = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_fp, (\u001b[38;5;28mstr\u001b[39m, pathlib.Path)):\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     stream = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath_or_fp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m     stream_is_external = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    100\u001b[39m     path = pathlib.Path(path_or_fp)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/pre_monsoon_1994_2003_split/pre_monsoon_1994_2003-2001-3047.pdf'"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "pdf_path = \"data/pre_monsoon_1994_2003_split/pre_monsoon_1994_2003-2001-3047.pdf\"\n",
    "\n",
    "output_csv_path = r\"D:\\\\pdftoexcel\\\\data\\\\pre_monsoon_1994_2003_split\\\\csv_dataset\\\\extracted_data_2001_3047.csv\"\n",
    "\n",
    "extracted_data = []\n",
    "\n",
    "# Using a slightly more robust regex to handle different number formats\n",
    "line_pattern = re.compile(r'(\\d+\\.?\\d*)\\s+(\\d+\\.?\\d*)\\s+(\\d{2}-\\d{2}-\\d{2})\\s+([\\d\\.]+)$')\n",
    "\n",
    "# --- FIX: Define line_buffer OUTSIDE the page loop ---\n",
    "line_buffer = \"\"\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for page in pdf.pages:\n",
    "        text = page.extract_text()\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        raw_lines = text.split('\\n')\n",
    "        processed_lines = []\n",
    "        \n",
    "        for line in raw_lines:\n",
    "            line_buffer += \" \" + line.strip()\n",
    "            if line_pattern.search(line_buffer):\n",
    "                processed_lines.append(line_buffer.strip())\n",
    "                line_buffer = \"\" # Reset buffer ONLY after a successful record is found\n",
    "\n",
    "        for line in processed_lines:\n",
    "            match = line_pattern.search(line)\n",
    "            if match:\n",
    "                latitude, longitude, date, wl = match.groups()\n",
    "                location_info = line[:match.start()].strip()\n",
    "                \n",
    "                extracted_data.append({\n",
    "                    'Location_Info': location_info,\n",
    "                    'Latitude': latitude,\n",
    "                    'Longitude': longitude,\n",
    "                    'Date': date,\n",
    "                    'WL(mbgl)': wl\n",
    "                })\n",
    "\n",
    "if extracted_data:\n",
    "    df = pd.DataFrame(extracted_data)\n",
    "    df.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90b3506-1a33-45e1-ade0-58d1d551a0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
